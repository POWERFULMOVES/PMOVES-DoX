# Shared credentials for PMOVES services.
# Copy to `pmoves/env.shared` and fill in real values. The file is ignored by git.

## Supabase (remote / hybrid mode)
# Rotate Supabase CLI keys via `supabase start` / `make supa-start`, then copy
# the new values from `make supa-status` into these fields and run `make env-setup`.
SUPABASE_URL=https://your-supabase.example.com
SUPABASE_KEY=
SUPABASE_SERVICE_KEY=
SUPABASE_ANON_KEY=
NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}
NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
SUPABASE_REST_URL=http://localhost:3010
SUPA_REST_URL=${SUPABASE_REST_URL}
POSTGRES_HOSTNAME=supabase-db
POSTGRES_PORT=5432
POSTGRES_DB=cataclysm_pmoves
PGRST_JWT_SECRET=super-secret-jwt-token-with-at-least-32-characters-long
# Supabase boot operator (managed by `make supabase-boot-user` / `make first-run`)
# SUPABASE_BOOT_USER_EMAIL=operator@pmoves.local
# SUPABASE_BOOT_USER_PASSWORD=
# SUPABASE_BOOT_USER_JWT=
# SUPABASE_BOOT_USER_REFRESH=
# NEXT_PUBLIC_SUPABASE_BOOT_USER_JWT=${SUPABASE_BOOT_USER_JWT}

## Provider API keys (Open Notebook, Hi-RAG gateways, n8n flows, etc.)
# When rotating provider keys, update them here first, then in your CI secrets.
# See docs/SECRETS.md for a provider→env mapping and rotation notes.
# Common dashboards:
# - OPENAI_API_KEY: https://platform.openai.com/api-keys
# - GROQ_API_KEY: https://console.groq.com/keys
# - ANTHROPIC_API_KEY: https://console.anthropic.com/settings/keys
# - GEMINI_API_KEY / GOOGLE_API_KEY: https://aistudio.google.com/app/apikey
# - MISTRAL_API_KEY: https://console.mistral.ai/api-keys
# - DEEPSEEK_API_KEY: https://platform.deepseek.com/api-keys
# - OPENROUTER_API_KEY: https://openrouter.ai/keys
# - XAI_API_KEY: https://console.x.ai
# - ELEVENLABS_API_KEY: https://elevenlabs.io/app/api-keys
# - CLOUDFLARE_API_TOKEN: https://dash.cloudflare.com/profile/api-tokens
OPENAI_API_KEY=
OPENAI_API_BASE=
# Workers AI helper: OPENAI_API_BASE=https://api.cloudflare.com/client/v4/accounts/${CLOUDFLARE_ACCOUNT_ID}/ai
GROQ_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
GOOGLE_API_KEY=
MISTRAL_API_KEY=
DEEPSEEK_API_KEY=
# OpenRouter (DeepResearch + agent fallbacks). Required when using
# `DEEPRESEARCH_MODE=openrouter` or routing agent traffic through
# OpenRouter-hosted models.
OPENROUTER_API_KEY=
OPENROUTER_API_BASE=https://openrouter.ai/api
# Optional OpenRouter app metadata (displayed in provider dashboards).
OPENROUTER_APP_NAME=PMOVES DeepResearch
OPENROUTER_APP_URL=https://pmoves.ai
XAI_API_KEY=
ELEVENLABS_API_KEY=
VOYAGE_API_KEY=
COHERE_API_KEY=
FIREWORKS_AI_API_KEY=
PERPLEXITYAI_API_KEY=
TOGETHER_AI_API_KEY=
OLLAMA_BASE_URL=http://localhost:11434
OPENAI_COMPATIBLE_BASE_URL=
TENSORZERO_HOST_URL=http://localhost:3030
TENSORZERO_API_KEY=
TENSORZERO_MODEL=openai::gpt-4o-mini
TENSORZERO_TIMEOUT_SECONDS=60
# Comma-separated (key=value) or JSON string; forwarded to TensorZero as request tags.
TENSORZERO_STATIC_TAGS=
CLOUDFLARE_ACCOUNT_ID=
CLOUDFLARE_API_TOKEN=
CLOUDFLARE_LLM_MODEL=@cf/meta/llama-3.1-8b-instruct
MINDMAP_BASE=http://localhost:8086
MINDMAP_CONSTELLATION_ID=8c1b7a8c-7b38-4a6b-9bc3-3f1fdc9a1111
# Optional: Notebook ID for mindmap constellation sync (scripts/mindmap_to_notebook.py)
# Format: notebook:xxxxx (get from Open Notebook API or UI)
MINDMAP_NOTEBOOK_ID=
# Optional: Notebook ID for Hi-RAG search results sync (scripts/hirag_search_to_notebook.py)
HIRAG_NOTEBOOK_ID=
HIRAG_V2_HOST_PORT=8086
HIRAG_V2_GPU_HOST_PORT=8087
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=pmoves_chunks_qwen3

# Extract worker
# Host port for the /healthz + /ingest endpoints. Set to 18083 if 8083 is already in use.
EXTRACT_WORKER_HOST_PORT=8083
# Keep extract-worker embeddings aligned with hi-rag v2 defaults unless you explicitly opt into TensorZero.
EXTRACT_WORKER_EMBEDDING_BACKEND=tensorzero
# When using TensorZero embeddings, tune batching/timeouts if large ingests time out.
TENSORZERO_EMBED_BATCH_SIZE=16
TENSORZERO_EMBED_TIMEOUT_SECS=120

# ---- Model backends (defaults are safe/local) ----
# TensorZero (OpenAI-compatible) gateway. If running locally via `make up-tensorzero`,
# this will default to the in-cluster gateway. Set to a remote URL to use a remote stack.
TENSORZERO_BASE_URL=http://tensorzero-gateway:3000
# Voice Agents (n8n) default to TensorZero local models when available.
VOICE_AGENT_MODEL=tensorzero::model_name::qwen2_5_14b
# Default embedding route for TensorZero's OpenAI-compatible API.
# Production default (RTX 5090 class): Qwen3-Embedding via Ollama, routed through TensorZero for observability.
TENSORZERO_EMBED_MODEL=tensorzero::embedding_model_name::qwen3_embedding_4b_local
# ClickHouse target for TensorZero gateway metrics
TENSORZERO_CLICKHOUSE_URL=http://tensorzero-clickhouse:8123
TENSORZERO_CLICKHOUSE_USER=tensorzero
TENSORZERO_CLICKHOUSE_PASSWORD=tensorzero
TENSORZERO_CLICKHOUSE_DB=tensorzero
LANGEXTRACT_PROVIDER=rule

# Ollama local models. `make up-tensorzero` also launches a bundled Ollama sidecar.
OLLAMA_URL=http://ollama:11434
# Production default (RTX 5090 class): Qwen3-Embedding 4B. For edge/Jetson, prefer `qwen3-embedding:0.6b` or `embeddinggemma:300m`.
OLLAMA_EMBED_MODEL=qwen3-embedding:4b

# Generic OpenAI-compatible gateway (LM Studio, vLLM, NIM, etc.)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=
OPENAI_COMPAT_EMBED_MODEL=text-embedding-3-small

# Hi‑RAG v2 reranking/embedding tuning
RERANK_ENABLE=true
# GPU default: Qwen 4B reranker stored on the GPU node under /models/qwen.
RERANK_MODEL=Qwen/Qwen3-Reranker-4B
RERANK_MODEL_PATH=/models/qwen/Qwen3-Reranker-4B
# Override when the container needs to force CPU execution (otherwise auto-selects based on CUDA availability).
RERANK_USE_FP16=true
RERANK_TOPN=50
RERANK_K=10
RERANK_FUSION=mul
SENTENCE_MODEL=all-MiniLM-L6-v2

# ---- Agent UI images (published) ----
# Override to use published images for headless+UI builds instead of building locally.
# Example stable tags (adjust as your registry publishes):
AGENT_ZERO_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-agent-zero:2025.12.13
ARCHON_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-archon:2025.12.13
ARCHON_UI_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-archon-ui:2025.12.13
DEEPRESEARCH_IMAGE=ghcr.io/powerfulmoves/pmoves-deepresearch:stable
SUPASERCH_IMAGE=ghcr.io/powerfulmoves/pmoves-supaserch:stable

# Console tiles (override if agents are on remote hosts)
NEXT_PUBLIC_AGENT_ZERO_URL=http://localhost:8080
NEXT_PUBLIC_ARCHON_URL=http://localhost:8091
# Optional custom health paths for UI badges (fallbacks: /healthz, /api/health, /)
NEXT_PUBLIC_AGENT_ZERO_HEALTH_PATH=/healthz
NEXT_PUBLIC_ARCHON_HEALTH_PATH=/healthz

# Server-side REST base for direct PostgREST queries (fallback for console pages)
# If using compose PostgREST, this should be http://localhost:3010
POSTGREST_URL=http://localhost:3010

# Agent Zero native UI URL (upstream runtime UI). API remains on :8080 by default.
NEXT_PUBLIC_AGENT_ZERO_UI_URL=http://localhost:8081
NEXT_PUBLIC_ARCHON_UI_URL=http://localhost:3737

# Agent Zero MCP servers (semicolon-delimited key: url pairs). Example includes Archon MCP over HTTP.
# A0_MCP_SERVERS=
#   fs: "mcp://filesystem?roots=/data";
#   archon: "mcp://http?endpoint=http://archon-server:8051";
#   neo4j: "mcp://neo4j?url=bolt://neo4j:7687&user=neo4j&password=${NEO4J_PASSWORD}";
#   supabase: "mcp://supabase?url=${SUPABASE_URL}&key=${SUPABASE_SERVICE_ROLE_KEY}";

# UI smoke/health
SMOKE_SHARED_SECRET=change-me-for-local-smoke

# Console mode
# SINGLE_USER_MODE=1 enables personal-first UX with boot-JWT auto-auth and hides login prompts.
SINGLE_USER_MODE=1
NEXT_PUBLIC_SINGLE_USER_MODE=1

# PMOVES.YT (optional published image)
PMOVES_YT_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-yt:2025.12.13

## Open Notebook
# Knowledge management system using SurrealDB backend
# See: docs/services/open-notebook/ for integration details
OPEN_NOTEBOOK_IMAGE=ghcr.io/powerfulmoves/pmoves-open-notebook:v1-latest
# REQUIRED: API endpoint (used by notebook-sync, deepresearch, agent-zero, UI)
# Without this, notebook-sync runs in offline mode (no syncing)
OPEN_NOTEBOOK_API_URL=http://cataclysm-open-notebook:5055
# REQUIRED: Bearer token for API authentication
# Must be set for DeepResearch → Notebook publishing to work
OPEN_NOTEBOOK_API_TOKEN=
# Optional: Password for web UI login
OPEN_NOTEBOOK_PASSWORD=changeme
# Local SurrealDB defaults (override when pointing at an external Surreal instance)
OPEN_NOTEBOOK_SURREAL_URL=ws://cataclysm-open-notebook-surrealdb:8000/rpc
OPEN_NOTEBOOK_SURREAL_ADDRESS=cataclysm-open-notebook-surrealdb
OPEN_NOTEBOOK_SURREAL_PORT=8000
OPEN_NOTEBOOK_SURREAL_USER=root
OPEN_NOTEBOOK_SURREAL_PASS=root
OPEN_NOTEBOOK_SURREAL_NAMESPACE=open-notebook
OPEN_NOTEBOOK_SURREAL_DATABASE=open-notebook
# Legacy aliases consumed by older scripts and compose files.
# NOTE: env_file parsing does not expand `${VAR}` references, so keep these concrete.
SURREAL_URL=ws://cataclysm-open-notebook-surrealdb:8000/rpc
SURREAL_ADDRESS=cataclysm-open-notebook-surrealdb
SURREAL_PORT=8000
SURREAL_USER=root
SURREAL_PASS=root
SURREAL_NAMESPACE=open-notebook
SURREAL_DATABASE=open-notebook

## DeepResearch integration
# Mode: tensorzero (local Ollama), openrouter (cloud), or local (external API)
DEEPRESEARCH_MODE=tensorzero
DEEPRESEARCH_TIMEOUT=600

# TensorZero/Ollama configuration (default mode)
# Use tensorzero::model_name:: prefix for TensorZero model routing
DEEPRESEARCH_TENSORZERO_BASE_URL=http://tensorzero-gateway:3030
DEEPRESEARCH_TENSORZERO_MODEL=tensorzero::model_name::nemotron_mini
DEEPRESEARCH_TENSORZERO_FALLBACK_MODEL=tensorzero::model_name::qwen3_8b
# Models: nemotron-mini (2.7GB, efficient), qwen3:8b (5.2GB, capable)

# OpenRouter configuration (mode=openrouter)
DEEPRESEARCH_OPENROUTER_MODEL=tongyi-deepresearch
DEEPRESEARCH_OPENROUTER_API_BASE=https://openrouter.ai/api

# Local API configuration (mode=local)
DEEPRESEARCH_API_BASE=http://deepresearch-local:8080
DEEPRESEARCH_PLANNING_ENDPOINT=/api/research
# REQUIRED for DeepResearch → Notebook integration
# Format: notebook:xxxxx (create via Open Notebook UI or API)
# DeepResearch will publish research summaries to this notebook as sources
DEEPRESEARCH_NOTEBOOK_ID=
# Optional: Prefix for source titles (default: DeepResearch)
DEEPRESEARCH_NOTEBOOK_TITLE_PREFIX=DeepResearch
# Optional: Whether to embed sources (default: true)
DEEPRESEARCH_NOTEBOOK_EMBED=true
# Optional: Whether to publish asynchronously (default: true)
DEEPRESEARCH_NOTEBOOK_ASYNC=true

## Channel monitor
CHANNEL_MONITOR_CONFIG_PATH=/app/config/channel_monitor.json
CHANNEL_MONITOR_QUEUE_URL=http://pmoves-yt:8077/yt/ingest
CHANNEL_MONITOR_DATABASE_URL=postgresql://postgres:postgres@host.docker.internal:65432/postgres
CHANNEL_MONITOR_NAMESPACE=pmoves
CHANNEL_MONITOR_SECRET=
CHANNEL_MONITOR_STATUS_URL=http://channel-monitor:8097/api/monitor/status
CHANNEL_MONITOR_STATUS_SECRET=
CHANNEL_MONITOR_GOOGLE_CLIENT_ID=YOUR_GOOGLE_CLIENT_ID_HERE.apps.googleusercontent.com
CHANNEL_MONITOR_GOOGLE_CLIENT_SECRET=GOCSPX-YOUR_CLIENT_SECRET_HERE
CHANNEL_MONITOR_GOOGLE_REDIRECT_URI=http://localhost:8097/api/oauth/google/callback
CHANNEL_MONITOR_GOOGLE_SCOPES=https://www.googleapis.com/auth/youtube.readonly
# Google Cloud prerequisites: configure the OAuth 2.0 consent screen and enable the YouTube Data API.

# pmoves-yt ↔ channel monitor callback
CHANNEL_MONITOR_STATUS_URL=http://channel-monitor:8097/api/monitor/status
CHANNEL_MONITOR_STATUS_SECRET=

# yt-dlp feature toggles
YT_CONCURRENCY=2
YT_RATE_LIMIT=0.0
YT_ARCHIVE_DIR=/data/yt-dlp
YT_ENABLE_DOWNLOAD_ARCHIVE=true
YT_DOWNLOAD_ARCHIVE=
YT_SUBTITLE_LANGS=en
YT_SUBTITLE_AUTO=false
YT_WRITE_INFO_JSON=true
YT_POSTPROCESSORS_JSON=
YT_UPSERT_BATCH_SIZE=200
YT_ASYNC_UPSERT_ENABLED=true
YT_ASYNC_UPSERT_MIN_CHUNKS=200
YT_INDEX_LEXICAL_DISABLE_THRESHOLD=0
SOUNDCLOUD_USERNAME=
SOUNDCLOUD_PASS=
INVIDIOUS_BASE_URL=https://yewtu.be
INVIDIOUS_COMPANION_URL=
INVIDIOUS_COMPANION_KEY=
INVIDIOUS_FALLBACK_FORMAT=video/mp4
INVIDIOUS_HMAC_KEY=
INVIDIOUS_PG_DB=invidious
INVIDIOUS_PG_USER=kemal
INVIDIOUS_PG_PASSWORD=kemal
INVIDIOUS_COMPANION_PUBLIC_URL=http://localhost:8282
INVIDIOUS_COMPANION_LISTEN=127.0.0.1:8282

# -------- Monitoring (Grafana/Prometheus/Loki) --------
PROMETHEUS_HOST_PORT=9090
GRAFANA_HOST_PORT=3002
LOKI_HOST_PORT=3100
CADVISOR_HOST_PORT=9180

# Optional: OpenTelemetry (future)
#OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
#OTEL_SERVICE_NAME=pmoves
INVIDIOUS_BIND=127.0.0.1:3005
INVIDIOUS_EXTERNAL_PORT=3005
INVIDIOUS_DOMAIN=
INVIDIOUS_HTTPS_ONLY=false
INVIDIOUS_STATISTICS_ENABLED=false
INVIDIOUS_USE_INNERTUBE_CAPTIONS=true
INVIDIOUS_USE_REDIRECTOR=true
INVIDIOUS_REDIRECTOR_URL=https://redirect.invidious.io
YT_ENABLE_PO_TOKEN=true
YT_PO_TOKEN_VALUE=
YT_PO_TOKEN_ITAG=18
# Gemma summarization providers
YT_GEMMA_MODEL=gemma2:9b-instruct
HF_GEMMA_MODEL=google/gemma-2-9b-it
FFW_PROVIDER=faster-whisper
WHISPER_MODEL=small
YT_TRANSCRIPT_PROVIDER=faster-whisper
YT_WHISPER_MODEL=small
YT_TRANSCRIPT_DIARIZE=false
# Qwen2‑Audio transcription (ffmpeg‑whisper)
QWEN2_AUDIO_MODEL=Qwen/Qwen2-Audio-7B-Instruct
QWEN2_AUDIO_MAX_NEW_TOKENS=512
GRAYJAY_PLUGIN_HOST_PUBLIC_URL=http://localhost:9096
GRAYJAY_PLUGIN_REGISTRY_TITLE=PMOVES Plugin Registry
GRAYJAY_PLUGIN_REGISTRY_URL=http://grayjay-plugin-host:8080/plugins
GRAYJAY_JELLYFIN_PLUGIN_NAME=PMOVES Jellyfin
GRAYJAY_JELLYFIN_PLUGIN_ID=pmoves-jellyfin
GRAYJAY_JELLYFIN_PLUGIN_DESCRIPTION=Self-hosted Jellyfin connector for PMOVES
GRAYJAY_SERVER_BIND=0.0.0.0
GRAYJAY_SERVER_PORT=9095

## n8n
N8N_API_KEY=
N8N_RUNNERS_AUTH_TOKEN=
N8N_ENCRYPTION_KEY=
# n8n persistence mode:
# - sqlite (default): quickest local bring-up
# - postgres: recommended for VPS/prod (uses pmoves/docker-compose.n8n.postgres.yml)
N8N_DB=sqlite
N8N_DB_NAME=
N8N_DB_USER=
N8N_DB_PASSWORD=
N8N_DB_SCHEMA=public
# Optional: enable chat-platform voice agent flows (Discord/Telegram) in n8n activation helper.
# Default is disabled to keep the stack green when credentials/custom nodes are not present.
VOICE_PLATFORMS=0
# If you want to protect the n8n UI with Basic Auth (recommended for non-local deployments):
N8N_BASIC_AUTH_ACTIVE=false
N8N_BASIC_AUTH_USER=
N8N_BASIC_AUTH_PASSWORD=

## Domain integrations
WGER_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-health-wger:pmoves-latest
WGER_SITE_URL=http://localhost:8000
WGER_FROM_EMAIL="PMOVES Health Coach <health@example.com>"
WGER_BRAND_SITE_NAME=PMOVES Health Portal
WGER_BRAND_GYM_NAME=PMOVES Health Lab
WGER_BRAND_GYM_CITY=Distributed Mesh
WGER_BRAND_ADMIN_FIRST_NAME=PMOVES
WGER_BRAND_ADMIN_LAST_NAME=Ops
WGER_BRAND_ADMIN_EMAIL=admin@example.com
WGER_BRAND_ADMIN_USERNAME=admin
WGER_BRAND_WAIT_SECS=90
WGER_API_TOKEN=
FIREFLY_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-firefly-iii:pmoves-latest
FIREFLY_ACCESS_TOKEN=
FIREFLY_CMD_LN_TOKEN=
FIREFLY_PA_TOKEN_NAME=
FIREFLY_PORT=8082

## Discord publisher
DISCORD_WEBHOOK_URL=
DISCORD_USERNAME=PMOVES Publisher
DISCORD_AVATAR_URL=https://example.com/avatar.png

## Jellyfin
JELLYFIN_PUBLIC_BASE_URL=http://localhost:8096
JELLYFIN_URL=http://cataclysm-jellyfin:8096
JELLYFIN_IMAGE=ghcr.io/cataclysm-studios-inc/pmoves-jellyfin:pmoves-latest
JELLYFIN_PUBLISHED_URL=
JELLYFIN_API_KEY=
JELLYFIN_USER_ID=

## Misc (MinIO, etc.)
# Unified storage: point S3-compatible clients at Supabase Storage (CLI stack on 65421).
MINIO_ENDPOINT=http://host.docker.internal:65421/storage/v1/s3
MINIO_REGION=local
MINIO_SECURE=false
MINIO_USER=cataclysm_pmoves
MINIO_PASSWORD=
# Services use the S3-compatible names; keep these in sync with MINIO_USER/MINIO_PASSWORD.
MINIO_ACCESS_KEY=
MINIO_SECRET_KEY=
# Local MinIO root credentials (used only when running the local minio service profile).
MINIO_ROOT_USER=
MINIO_ROOT_PASSWORD=
VALID_API_KEYS=
NEXT_PUBLIC_BACKEND_API_KEY=

## CHIT (production)
CHIT_PASSPHRASE=
CHIT_REQUIRE_SIGNATURE=false

## Flute (realtime voice gateway)
# VibeVoice typically runs outside Docker (Pinokio/host) on port 3000.
VIBEVOICE_URL=http://host.docker.internal:3000
# Optional: run VibeVoice in Docker (downloads large model weights on first run).
# Start it with: `make -C pmoves up-vibevoice`
# Host port for the VibeVoice Docker service (container listens on 3000).
VIBEVOICE_HOST_PORT=3000
# Optional Hugging Face token (only needed for gated models).
HF_TOKEN=
# Optional build/runtime overrides for the VibeVoice container.
VIBEVOICE_MODEL_ID=microsoft/VibeVoice-Realtime-0.5B
VIBEVOICE_GIT_REMOTE=https://github.com/microsoft/VibeVoice.git
VIBEVOICE_GIT_REF=main
# Device selection for the VibeVoice container: auto|cpu|cuda
VIBEVOICE_DEVICE=auto
# ffmpeg-whisper runs in Docker by default.
WHISPER_URL=http://ffmpeg-whisper:8078
DEFAULT_VOICE_PROVIDER=vibevoice
FLUTE_API_KEY=

# Optional: host-run voice speaker (plays audio on your machine; useful for realtime local playback)
# Start: `make -C pmoves voice-speaker-start` then speak: `make -C pmoves voice-say MSG="Hello"`
FLUTE_BASE_URL=http://localhost:8055
VOICE_SPEAKER_BIND=127.0.0.1
VOICE_SPEAKER_PORT=8120

# Optional: host-run voice-follow daemon (speaks incoming NATS responses)
# Start the speaker first, then:
#   `make -C pmoves voice-follow-start`
# Stop:
#   `make -C pmoves voice-follow-stop`
VOICE_SPEAKER_URL=http://127.0.0.1:8120
VOICE_FOLLOW_SUBJECTS=voice.agent.response.v1,agent.response.v1

## Creator workstation (optional)
# ComfyUI docker service (optional; used by n8n pmoves_comfy_gen flow). Defaults are chosen for local dev.
# Start it with: `make -C pmoves up-comfyui`
COMFYUI_HOST_PORT=8188
COMFYUI_IMAGE=runpod/comfyui:latest

# Ultimate TTS Studio UI (optional; hardened fork image).
# Start it with: `make -C pmoves up-tts-studio`
ULTIMATE_TTS_STUDIO_HOST_PORT=7861
ULTIMATE_TTS_STUDIO_IMAGE=ghcr.io/powerfulmoves/pmoves-ultimate-tts-studio:pmoves-latest

## CI / Registries (for GHCR publish workflows)
GHCR_USERNAME=
GH_PAT_PUBLISH=

## Cloudflare tunnel (optional remote access)
# Preferred: token-based connector generated from Zero Trust → Access → Tunnels → Add a connector (Docker).
CLOUDFLARE_TUNNEL_TOKEN=
# Alternative: supply a tunnel name and credentials directory when using cert-based auth.
CLOUDFLARE_TUNNEL_NAME=
CLOUDFLARE_CREDENTIALS_DIR=./cloudflared
# Optional ingress overrides (comma-separated entries like service=url).
CLOUDFLARE_TUNNEL_INGRESS=
CLOUDFLARE_TUNNEL_HOSTNAMES=
CLOUDFLARE_TUNNEL_METRICS_PORT=
# -------- Tailscale (optional) --------
TAILSCALE_AUTO_JOIN=false
TAILSCALE_AUTHKEY=
TAILSCALE_AUTHKEY_FILE=CATACLYSM_STUDIOS_INC/PMOVES-PROVISIONS/tailscale/tailscale_authkey.txt
TAILSCALE_TAGS=tag:pmoves
TAILSCALE_HOSTNAME=
TAILSCALE_ACCEPT_ROUTES=true
TAILSCALE_ADVERTISE_ROUTES=
TAILSCALE_LOGIN_SERVER=
TAILSCALE_SSH=true
TAILSCALE_SIGN_AUTHKEY=auto
# retrieval-eval
EVAL_HTTP_PORT=8090
