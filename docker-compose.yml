
services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.gpu
    container_name: pmoves-dox-backend
    volumes:
      - ./backend/uploads:/app/uploads
      - ./backend/artifacts:/app/artifacts
      - ./backend/app:/app/app
      - ./backend/data:/app/data
      - hf-cache:/root/.cache/huggingface
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@supabase-db:5432/postgres
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
      - FRONTEND_ORIGIN=http://localhost:${FRONTEND_PORT:-3001},http://127.0.0.1:${FRONTEND_PORT:-3001}
      - PORT=${BACKEND_PORT:-8484}
      - HUGGINGFACE_HUB_TOKEN=${HF_API_KEY:-${HUGGINGFACE_HUB_TOKEN:-}}
      - DOCLING_VLM_REPO=${DOCLING_VLM_REPO:-}
      - OLLAMA_BASE_URL=http://ollama:11434
      - AUTO_MIGRATE=${AUTO_MIGRATE:-false}
      - HRM_ENABLED=${HRM_ENABLED:-false}
      - HRM_MMAX=${HRM_MMAX:-6}
      - HRM_MMIN=${HRM_MMIN:-2}
      - XML_XPATH_MAP=${XML_XPATH_MAP:-}
      - XML_XPATH_MAP_FILE=${XML_XPATH_MAP_FILE:-}
      - OPEN_PDF_ENABLED=${OPEN_PDF_ENABLED:-false}
    ports:
      - "0:8484"
    networks:
      - api_tier
      - app_tier
      - bus_tier
      - data_tier
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      - supabase-db
      - nats
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:8484/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_BASE: /api
        NEXT_PUBLIC_NATS_WS_URL: ws://localhost:9223
    container_name: pmoves-dox-frontend
    environment:
      - API_URL=http://backend:8484
      - NEXT_PUBLIC_API_BASE=/api
      - NEXT_PUBLIC_NATS_WS_URL=ws://localhost:9223
      - PORT=3001
    ports:
      - "0:3001"
    networks:
      - api_tier
    depends_on:
      - backend
    restart: unless-stopped

  nats:
    image: nats:latest
    container_name: pmoves-dox-nats
    command: -c /etc/nats/nats.conf
    ports:
      - "4223:4222"
      - "8223:8222"
      - "9223:9222"
    volumes:
      - ./backend/nats-config/nats.conf:/etc/nats/nats.conf
    networks:
      - bus_tier
      - api_tier
    restart: unless-stopped

  supabase-db:
    image: supabase/postgres:15.1.0.117
    container_name: supabase-db
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
    networks:
      - data_tier
    volumes:
      - supabase_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  supabase-rest:
    image: postgrest/postgrest:v11.1.0
    container_name: supabase-rest
    environment:
      PGRST_DB_URI: postgres://postgres:${POSTGRES_PASSWORD:-postgres}@supabase-db:5432/postgres
      PGRST_DB_SCHEMA: public,storage,graphql_public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${PGRST_JWT_SECRET}
    ports:
      - "54321:3000"
    networks:
      - api_tier
      - data_tier
    depends_on:
      - supabase-db

  cipher-service:
    container_name: pmoves-dox-cipher
    image: cipher-api
    build:
      context: ./PsyFeR_reference
      dockerfile: Dockerfile
    # Internal service: No ports exposed to host. Reachable via http://cipher-service:3000 on app_tier
    networks:
      - app_tier
    environment:
      - CIPHER_API_PREFIX=""
      - NODE_ENV=production
    volumes:
      - ./backend/cipher-config/cipher.yml:/app/memAgent/cipher.yml
      - cipher-data:/app/.cipher
    depends_on:
      - ollama
      - nats
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: pmoves-dox-ollama-1
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - api_tier
      - app_tier
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped




  glances:
    image: nicolargo/glances:latest-full
    container_name: pmoves-dox-glancer
    ports:
      - "61208:61208"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./external/Pmoves-Glancer/glances.conf:/glances/conf/glances.conf
    environment:
      - GLANCES_OPT=-C /glances/conf/glances.conf -w
      - TZ=America/New_York
    networks:
      - api_tier
      - app_tier
      - bus_tier
    restart: unless-stopped

  datavzrd:
    build:
      context: ./tools/datavzrd
      dockerfile: Dockerfile
    container_name: datavzrd
    profiles: ["tools"]
    environment:
      - VIZ_FILE=
    volumes:
      - ./backend/artifacts:/app/artifacts
    ports:
      - "5173:5173"
    networks:
      - app_tier
    depends_on:
      - backend
    restart: unless-stopped

  schemavzrd:
    build:
      context: ./tools/schemavzrd
      dockerfile: Dockerfile
    container_name: schemavzrd
    profiles: ["tools"]
    environment:
      - DB_URL=${DB_URL:-}
      - OUTPUT_DIR=/app/out/schema
    volumes:
      - ./backend/artifacts:/app/out
    ports:
      - "5174:5174"
    networks:
      - app_tier
    restart: unless-stopped


  # Phase 9: Internal BoTZ Agents

  cipher:
    build:
      context: ./external/PMOVES-BotZ-gateway/sample-servers/mcp-proxy
    container_name: pmoves-botz-cipher
    environment:
      - MCP_COMMAND=python
      - MCP_ARGS=/app/cipher/app_memory.py
    ports:
      - "3025:8000"
    volumes:
      - ./external/PMOVES-BoTZ/features/cipher:/app/cipher
      - cipher-data:/data
    command: ["/usr/local/bin/fastmcp", "run", "src/main.py:app", "--transport", "streamable-http", "--port", "8000", "--host", "0.0.0.0"]
    networks:
      - app_tier
      - api_tier
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  postman-agent:
    build:
      context: ./external/PMOVES-BotZ-gateway/sample-servers/mcp-proxy
    container_name: pmoves-botz-postman
    environment:
      - MCP_COMMAND=npx
      - MCP_ARGS=@postman/postman-mcp-server@latest --full
      - POSTMAN_API_KEY=${POSTMAN_API_KEY}
    ports:
      - "3026:8000"
    networks:
      - app_tier
      - api_tier
    restart: unless-stopped

  docling:
    build:
      context: ./external/PMOVES-BoTZ/features/docling
      dockerfile: Dockerfile.docling-mcp
    container_name: pmoves-botz-docling
    ports:
      - "3020:8020"
    command: ["python", "docling_mcp_server.py", "--transport", "streamable-http", "--port", "8020", "--host", "0.0.0.0"]
    networks:
      - app_tier
      - api_tier
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8020/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  tensorzero:
    image: tensorzero/server:latest
    container_name: pmoves-botz-tensorzero
    ports:
      - "3000:3000"
    volumes:
      - ./external/PMOVES-BoTZ/config/tensorzero.toml:/app/config/tensorzero.toml
    environment:
      - TENSORZERO_PROVIDER_OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - app_tier
      - api_tier
    restart: unless-stopped

  agent-zero:
    build:
      context: ./external/PMOVES-Agent-Zero
      dockerfile: DockerfileLocal
    container_name: pmoves-agent-zero
    ports:
      - "50051:50051" # Agent Zero MCP/Web UI endpoint
    volumes:
      - ./external/PMOVES-Agent-Zero:/app
      - agent-zero-data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - PROFILE=pmoves_custom
      # MCP Server Configuration (docking pattern)
      - MCP_SERVER_ENABLED=${AGENT_ZERO_MCP_ENABLED:-false}
      - MCP_SERVER_TOKEN=${AGENT_ZERO_MCP_TOKEN:-}
      # Standalone mode uses Web UI on WEB_UI_PORT (default 50051)
      # Docked mode exposes MCP at http://pmoves-agent-zero:50051/mcp/t-{token}/sse
      - WEB_UI_PORT=50051
      # TensorZero integration for LLM orchestration
      - TENSORZERO_API_BASE=http://tensorzero:3000/v1
    networks:
      - app_tier
      - api_tier
      - bus_tier
    depends_on:
      - tensorzero
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:50051/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  api_tier:
    driver: bridge
    name: pmoves_api
    ipam:
      config:
        - subnet: 172.30.1.0/24

  app_tier:
    driver: bridge
    name: pmoves_app
    internal: true
    ipam:
      config:
        - subnet: 172.30.2.0/24

  bus_tier:
    driver: bridge
    name: pmoves_bus
    internal: true
    ipam:
      config:
        - subnet: 172.30.3.0/24

  data_tier:
    driver: bridge
    name: pmoves_data
    internal: true
    ipam:
      config:
        - subnet: 172.30.4.0/24

  monitoring_tier:
    driver: bridge
    name: pmoves_monitoring
    ipam:
      config:
        - subnet: 172.30.5.0/24

volumes:
  hf-cache:
  ollama:
  cipher-data:
  supabase_data:
  nats_data:
  ollama_data:
  agent-zero-data:
